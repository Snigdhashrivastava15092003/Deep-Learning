{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Fkxg7MoHSr"
      },
      "source": [
        "## Vgg16 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atLuOotgN_R6",
        "outputId": "4bc75bd1-8cc3-4b46-8c73-b3394a158207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1021 images belonging to 2 classes.\n",
            "Found 254 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 692s 22s/step - loss: 1.8883 - accuracy: 0.6724 - val_loss: 0.2990 - val_accuracy: 0.8393\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 682s 22s/step - loss: 0.3899 - accuracy: 0.8311 - val_loss: 0.3505 - val_accuracy: 0.8482\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 683s 22s/step - loss: 0.3184 - accuracy: 0.8534 - val_loss: 0.3187 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 682s 22s/step - loss: 0.2720 - accuracy: 0.8868 - val_loss: 0.2951 - val_accuracy: 0.8616\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 686s 22s/step - loss: 0.2386 - accuracy: 0.8999 - val_loss: 0.3479 - val_accuracy: 0.8304\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 702s 23s/step - loss: 0.2055 - accuracy: 0.9151 - val_loss: 0.3329 - val_accuracy: 0.8571\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 709s 23s/step - loss: 0.2143 - accuracy: 0.9019 - val_loss: 0.3382 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 672s 22s/step - loss: 0.1940 - accuracy: 0.9161 - val_loss: 0.2810 - val_accuracy: 0.8839\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 692s 22s/step - loss: 0.2466 - accuracy: 0.8908 - val_loss: 0.3197 - val_accuracy: 0.8571\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 683s 22s/step - loss: 0.1869 - accuracy: 0.9130 - val_loss: 0.3125 - val_accuracy: 0.8482\n",
            "Found 182 images belonging to 2 classes.\n",
            "6/6 [==============================] - 95s 15s/step - loss: 0.2777 - accuracy: 0.8901\n",
            "Test accuracy: 0.8901098966598511\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Extract the provided zip file\n",
        "with zipfile.ZipFile('archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('archive (3)')\n",
        "\n",
        "# Define directories for train, validation, and test sets\n",
        "train_dir = 'archive (3)/train'\n",
        "val_dir = 'archive (3)/validation'\n",
        "test_dir = 'archive (3)/test'\n",
        "\n",
        "# Create validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Define the ratio of data to move to the validation set\n",
        "validation_split = 0.2\n",
        "\n",
        "# Move a portion of the training data to the validation directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_validation = int(len(files) * validation_split)\n",
        "    validation_files = files[:num_validation]\n",
        "    for file in validation_files:\n",
        "        src = os.path.join(class_dir, file)\n",
        "        dst = os.path.join(val_dir, class_name)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load pre-trained VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Freeze pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # 3 classes for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples // batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qttkc27NYB29"
      },
      "source": [
        "##LeNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKt8Qz6JVAOd",
        "outputId": "450c56fc-d30f-46ad-c2b4-5810b3a7ca49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1021 images belonging to 2 classes.\n",
            "Found 762 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 8s 201ms/step - loss: 0.6740 - accuracy: 0.5915 - val_loss: 0.6697 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 6s 185ms/step - loss: 0.6264 - accuracy: 0.6350 - val_loss: 0.6079 - val_accuracy: 0.6630\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 6s 199ms/step - loss: 0.5817 - accuracy: 0.6946 - val_loss: 0.5680 - val_accuracy: 0.7160\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 6s 187ms/step - loss: 0.5455 - accuracy: 0.7270 - val_loss: 0.6071 - val_accuracy: 0.6984\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 6s 186ms/step - loss: 0.5145 - accuracy: 0.7695 - val_loss: 0.6474 - val_accuracy: 0.6386\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 5s 148ms/step - loss: 0.5063 - accuracy: 0.7725 - val_loss: 0.5761 - val_accuracy: 0.7296\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 5s 146ms/step - loss: 0.4919 - accuracy: 0.7735 - val_loss: 0.6849 - val_accuracy: 0.6726\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 6s 183ms/step - loss: 0.4836 - accuracy: 0.7685 - val_loss: 0.6298 - val_accuracy: 0.6780\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 6s 181ms/step - loss: 0.4489 - accuracy: 0.7958 - val_loss: 0.5864 - val_accuracy: 0.7405\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 5s 147ms/step - loss: 0.4584 - accuracy: 0.7927 - val_loss: 0.5466 - val_accuracy: 0.7188\n",
            "Found 182 images belonging to 2 classes.\n",
            "6/6 [==============================] - 1s 80ms/step - loss: 0.4609 - accuracy: 0.7857\n",
            "Test accuracy: 0.7857142686843872\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Extract the provided zip file\n",
        "with zipfile.ZipFile('archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('archive (3)')\n",
        "\n",
        "# Define directories for train, validation, and test sets\n",
        "train_dir = 'archive (3)/train'\n",
        "val_dir = 'archive (3)/validation'\n",
        "test_dir = 'archive (3)/test'\n",
        "\n",
        "# Create validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Define the ratio of data to move to the validation set\n",
        "validation_split = 0.2  # You can adjust this ratio as needed\n",
        "\n",
        "# Move a portion of the training data to the validation directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_validation = int(len(files) * validation_split)\n",
        "    validation_files = files[:num_validation]\n",
        "    for file in validation_files:\n",
        "        src = os.path.join(class_dir, file)\n",
        "        dst = os.path.join(val_dir, class_name)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "        # Handle destination file already exists\n",
        "        dst_file = os.path.join(dst, file)\n",
        "        if os.path.exists(dst_file):\n",
        "            # Rename the file before moving it\n",
        "            base_name, ext = os.path.splitext(file)\n",
        "            new_name = base_name + '_1' + ext\n",
        "            dst_file = os.path.join(dst, new_name)\n",
        "\n",
        "        shutil.move(src, dst_file)\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 32, 32  # LeNet uses smaller input size\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# LeNet Model\n",
        "model = Sequential([\n",
        "    Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='relu'),\n",
        "    Dense(84, activation='relu'),\n",
        "    Dense(2, activation='softmax')  #  3 classes for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples // batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9HaYoi_YJkn"
      },
      "source": [
        "##AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0owG8BOYNEm",
        "outputId": "c2a0219a-7e80-4344-b7f3-c35b6d8f3ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1021 images belonging to 2 classes.\n",
            "Found 508 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 111s 3s/step - loss: 0.6570 - accuracy: 0.6097 - val_loss: 0.7223 - val_accuracy: 0.5917\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 118s 4s/step - loss: 0.5436 - accuracy: 0.7462 - val_loss: 0.6091 - val_accuracy: 0.7125\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 118s 4s/step - loss: 0.4610 - accuracy: 0.7978 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 116s 4s/step - loss: 0.5544 - accuracy: 0.7351 - val_loss: 0.5698 - val_accuracy: 0.7354\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 116s 4s/step - loss: 0.4887 - accuracy: 0.7634 - val_loss: 0.4520 - val_accuracy: 0.7854\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 116s 4s/step - loss: 0.4366 - accuracy: 0.8160 - val_loss: 0.4417 - val_accuracy: 0.7958\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 116s 4s/step - loss: 0.4485 - accuracy: 0.7994 - val_loss: 0.4457 - val_accuracy: 0.8104\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 117s 4s/step - loss: 0.4058 - accuracy: 0.8190 - val_loss: 0.4032 - val_accuracy: 0.8188\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 117s 4s/step - loss: 0.3823 - accuracy: 0.8352 - val_loss: 0.4896 - val_accuracy: 0.7792\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 117s 4s/step - loss: 0.4242 - accuracy: 0.8160 - val_loss: 0.5834 - val_accuracy: 0.6792\n",
            "Found 182 images belonging to 2 classes.\n",
            "6/6 [==============================] - 4s 609ms/step - loss: 0.5077 - accuracy: 0.7143\n",
            "Test accuracy: 0.7142857313156128\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Extract the provided zip file\n",
        "with zipfile.ZipFile('archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('archive (3)')\n",
        "\n",
        "# Define directories for train, validation, and test sets\n",
        "train_dir = 'archive (3)/train'\n",
        "val_dir = 'archive (3)/validation'\n",
        "test_dir = 'archive (3)/test'\n",
        "\n",
        "# Create validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Define the ratio of data to move to the validation set\n",
        "validation_split = 0.2  # You can adjust this ratio as needed\n",
        "\n",
        "# Move a portion of the training data to the validation directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_validation = int(len(files) * validation_split)\n",
        "    validation_files = files[:num_validation]\n",
        "    for file in validation_files:\n",
        "        src = os.path.join(class_dir, file)\n",
        "        timestamp = str(time.time()).replace('.', '')  # Append a timestamp to the file name\n",
        "        dst = os.path.join(val_dir, class_name, timestamp + '_' + file)\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 227, 227  # AlexNet uses larger input size\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# AlexNet Model\n",
        "model = Sequential([\n",
        "    Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    Conv2D(256, kernel_size=(5, 5), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    Conv2D(384, kernel_size=(3, 3), activation='relu'),\n",
        "    Conv2D(384, kernel_size=(3, 3), activation='relu'),\n",
        "    Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  #  3 classes for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples // batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq_cPWWhzvCK"
      },
      "source": [
        "## EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP_TcSVuz8h3",
        "outputId": "490f52a0-bbec-455b-8232-5fae847420f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (24.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "pip install efficientnet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5IuNd5700MN",
        "outputId": "3865c43e-8268-4811-9c7c-f2a799b8440c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1021 images belonging to 2 classes.\n",
            "Found 2286 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 297s 10s/step - loss: 6.2832 - accuracy: 0.5644 - val_loss: 6.3071 - val_accuracy: 0.5807\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 281s 9s/step - loss: 6.0953 - accuracy: 0.5613 - val_loss: 5.0712 - val_accuracy: 0.5410\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 288s 9s/step - loss: 5.9823 - accuracy: 0.5367 - val_loss: 5.4407 - val_accuracy: 0.5209\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 221s 7s/step - loss: 5.9338 - accuracy: 0.5404 - val_loss: 5.1174 - val_accuracy: 0.5365\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 279s 9s/step - loss: 5.9576 - accuracy: 0.5672 - val_loss: 5.6672 - val_accuracy: 0.5670\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 227s 7s/step - loss: 6.0919 - accuracy: 0.5341 - val_loss: 5.2148 - val_accuracy: 0.5567\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 233s 8s/step - loss: 6.2636 - accuracy: 0.5322 - val_loss: 6.5559 - val_accuracy: 0.4859\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 224s 7s/step - loss: 6.2480 - accuracy: 0.5302 - val_loss: 5.4357 - val_accuracy: 0.5463\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 280s 9s/step - loss: 6.4359 - accuracy: 0.5203 - val_loss: 6.8354 - val_accuracy: 0.4807\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 281s 9s/step - loss: 6.3609 - accuracy: 0.5309 - val_loss: 6.1037 - val_accuracy: 0.5505\n",
            "Found 182 images belonging to 2 classes.\n",
            "6/6 [==============================] - 12s 2s/step - loss: 6.0810 - accuracy: 0.5488\n",
            "Test accuracy: 0.5488096475601196\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from efficientnet.tfkeras import EfficientNetB0\n",
        "\n",
        "# Extract the provided zip file\n",
        "with zipfile.ZipFile('archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('archive (3)')\n",
        "\n",
        "# Define directories for train, validation, and test sets\n",
        "train_dir = 'archive (3)/train'\n",
        "val_dir = 'archive (3)/validation'\n",
        "test_dir = 'archive (3)/test'\n",
        "\n",
        "# Create validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Define the ratio of data to move to the validation set\n",
        "validation_split = 0.2  # You can adjust this ratio as needed\n",
        "\n",
        "# Move a portion of the training data to the validation directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_validation = int(len(files) * validation_split)\n",
        "    validation_files = files[:num_validation]\n",
        "    for file in validation_files:\n",
        "        src = os.path.join(class_dir, file)\n",
        "        timestamp = str(time.time()).replace('.', '')  # Append a timestamp to the file name\n",
        "        dst = os.path.join(val_dir, class_name, timestamp + '_' + file)\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 224, 224  # EfficientNetB0 input size\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Set class_mode to 'binary' for binary classification\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Set class_mode to 'binary' for binary classification\n",
        ")\n",
        "\n",
        "# EfficientNetB0 Model (Corrected final layer)\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "base_model.trainable = False  # Freeze the pre-trained weights\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)  # No activation function here (Corrected)\n",
        "])\n",
        "\n",
        "# Compile the model (Applying sigmoid during compilation)\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples // batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Set class_mode to 'binary' for binary classification\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyltqLjygoEL"
      },
      "source": [
        "## Inception net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2zFrmregtv-",
        "outputId": "c9b87172-c748-453b-ae47-598c6ba2e05e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1021 images belonging to 2 classes.\n",
            "Found 254 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 4s 0us/step\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 349s 11s/step - loss: 0.4044 - accuracy: 0.8413 - val_loss: 0.2401 - val_accuracy: 0.9018\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 306s 10s/step - loss: 0.1924 - accuracy: 0.9201 - val_loss: 0.1646 - val_accuracy: 0.9286\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 301s 10s/step - loss: 0.1520 - accuracy: 0.9393 - val_loss: 0.1433 - val_accuracy: 0.9420\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 337s 11s/step - loss: 0.1564 - accuracy: 0.9464 - val_loss: 0.1396 - val_accuracy: 0.9286\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 331s 11s/step - loss: 0.1462 - accuracy: 0.9393 - val_loss: 0.1285 - val_accuracy: 0.9464\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 302s 10s/step - loss: 0.1286 - accuracy: 0.9414 - val_loss: 0.1553 - val_accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 331s 11s/step - loss: 0.1135 - accuracy: 0.9606 - val_loss: 0.1288 - val_accuracy: 0.9554\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 301s 10s/step - loss: 0.1116 - accuracy: 0.9565 - val_loss: 0.1423 - val_accuracy: 0.9375\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 300s 10s/step - loss: 0.1007 - accuracy: 0.9555 - val_loss: 0.1640 - val_accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 300s 10s/step - loss: 0.1230 - accuracy: 0.9525 - val_loss: 0.1571 - val_accuracy: 0.9330\n",
            "Found 182 images belonging to 2 classes.\n",
            "6/6 [==============================] - 42s 7s/step - loss: 0.1347 - accuracy: 0.9231\n",
            "Test Accuracy: 0.9230769276618958\n",
            "Test Accuracy: 0.9230769276618958\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "# Extract the provided zip file\n",
        "with zipfile.ZipFile('archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('archive (3)')\n",
        "\n",
        "# Define directories for train, validation, and test sets\n",
        "train_dir = 'archive (3)/train'\n",
        "val_dir = 'archive (3)/validation'\n",
        "test_dir = 'archive (3)/test'\n",
        "\n",
        "# Create validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Define the ratio of data to move to the validation set\n",
        "validation_split = 0.2  # You can adjust this ratio as needed\n",
        "\n",
        "# Move a portion of the training data to the validation directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_validation = int(len(files) * validation_split)\n",
        "    validation_files = files[:num_validation]\n",
        "    for file in validation_files:\n",
        "        src = os.path.join(class_dir, file)\n",
        "        timestamp = str(time.time()).replace('.', '')  # Append a timestamp to the file name\n",
        "        dst = os.path.join(val_dir, class_name, timestamp + '_' + file)\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 299, 299  # InceptionV3 input size\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Ensure class_mode is set to 'binary'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Ensure class_mode is set to 'binary'\n",
        ")\n",
        "\n",
        "# InceptionV3 Model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "base_model.trainable = False  # Freeze the pre-trained weights\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Add activation='sigmoid' for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples // batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Ensure class_mode is set to 'binary'\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqY-Snwmw8bt"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuTlbp5cxf19",
        "outputId": "e3031b2b-833e-48ec-b631-733e02e8c239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1021 images belonging to 2 classes.\n",
            "Found 508 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 342s 11s/step - loss: 0.7837 - accuracy: 0.5683 - val_loss: 0.5902 - val_accuracy: 0.6833\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 283s 9s/step - loss: 0.6670 - accuracy: 0.6694 - val_loss: 0.5675 - val_accuracy: 0.7146\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 283s 9s/step - loss: 0.5606 - accuracy: 0.7159 - val_loss: 0.5169 - val_accuracy: 0.7542\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 337s 11s/step - loss: 0.5499 - accuracy: 0.7482 - val_loss: 0.5021 - val_accuracy: 0.7729\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 281s 9s/step - loss: 0.5504 - accuracy: 0.7341 - val_loss: 0.4998 - val_accuracy: 0.7729\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 334s 11s/step - loss: 0.5508 - accuracy: 0.7209 - val_loss: 0.4989 - val_accuracy: 0.7729\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 336s 11s/step - loss: 0.5372 - accuracy: 0.7381 - val_loss: 0.5055 - val_accuracy: 0.7812\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 336s 11s/step - loss: 0.5550 - accuracy: 0.7321 - val_loss: 0.5279 - val_accuracy: 0.7771\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 336s 11s/step - loss: 0.5548 - accuracy: 0.7260 - val_loss: 0.4927 - val_accuracy: 0.7854\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 336s 11s/step - loss: 0.5333 - accuracy: 0.7361 - val_loss: 0.5097 - val_accuracy: 0.7854\n",
            "Found 182 images belonging to 2 classes.\n",
            "6/6 [==============================] - 34s 5s/step - loss: 0.5193 - accuracy: 0.7527\n",
            "Test Accuracy: 0.7527472376823425\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Extract the provided zip file\n",
        "with zipfile.ZipFile('archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('archive (3)')\n",
        "\n",
        "# Define directories for train, validation, and test sets\n",
        "train_dir = 'archive (3)/train'\n",
        "val_dir = 'archive (3)/validation'\n",
        "test_dir = 'archive (3)/test'\n",
        "\n",
        "# Create validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Define the ratio of data to move to the validation set\n",
        "validation_split = 0.2  # You can adjust this ratio as needed\n",
        "\n",
        "# Move a portion of the training data to the validation directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_validation = int(len(files) * validation_split)\n",
        "    validation_files = files[:num_validation]\n",
        "    for file in validation_files:\n",
        "        src = os.path.join(class_dir, file)\n",
        "        timestamp = str(time.time()).replace('.', '')\n",
        "        dst = os.path.join(val_dir, class_name, timestamp + '_' + file)\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# ResNet50 Model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "base_model.trainable = False  # Freeze the pre-trained weights\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples // batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Ensure class_mode is set to 'binary'\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}