{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "akdduB1vEcZK",
        "outputId": "40f02c5e-c6d3-4f58-aab9-c3bf0459399c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1021 images belonging to 2 classes.\n",
            "Found 254 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 694s 22s/step - loss: 1.5003 - accuracy: 0.6906 - val_loss: 0.2754 - val_accuracy: 0.9018\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 687s 22s/step - loss: 0.4246 - accuracy: 0.8342 - val_loss: 0.8364 - val_accuracy: 0.6339\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 662s 21s/step - loss: 0.4653 - accuracy: 0.8069 - val_loss: 0.2634 - val_accuracy: 0.8929\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 661s 21s/step - loss: 0.3250 - accuracy: 0.8665 - val_loss: 0.2445 - val_accuracy: 0.8839\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 679s 22s/step - loss: 0.2290 - accuracy: 0.9052 - val_loss: 0.3461 - val_accuracy: 0.8661\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 677s 22s/step - loss: 0.2282 - accuracy: 0.9009 - val_loss: 0.2783 - val_accuracy: 0.8795\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 679s 22s/step - loss: 0.2049 - accuracy: 0.9060 - val_loss: 0.2555 - val_accuracy: 0.8973\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 680s 22s/step - loss: 0.2196 - accuracy: 0.9029 - val_loss: 0.2630 - val_accuracy: 0.8839\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9050 "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Extract the provided zip file\n",
        "with zipfile.ZipFile('archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('archive (3)')\n",
        "\n",
        "# Define directories for train, validation, and test sets\n",
        "train_dir = 'archive (3)/train'\n",
        "val_dir = 'archive (3)/validation'\n",
        "test_dir = 'archive (3)/test'\n",
        "\n",
        "# Create validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Define the ratio of data to move to the validation set\n",
        "validation_split = 0.2\n",
        "\n",
        "# Move a portion of the training data to the validation directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_validation = int(len(files) * validation_split)\n",
        "    validation_files = files[:num_validation]\n",
        "    for file in validation_files:\n",
        "        src = os.path.join(class_dir, file)\n",
        "        dst = os.path.join(val_dir, class_name)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load pre-trained VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Freeze pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=train_generator.samples // batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}